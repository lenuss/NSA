{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************************************************************************\n",
    "# \n",
    "# Project to course Neural networks in applications\n",
    "# \n",
    "# Author: Bistakova Lenka, Brnovik Diana\n",
    "# PEF MENDELU 2020\n",
    "# \n",
    "# Used dataset: Student Alcohol Consumption - Portuguese language course dataset\n",
    "# URL of dataset: https://data.world/data-society/student-alcohol-consumption\n",
    "# \n",
    "# *********************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import neurolab as nl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(list): \n",
    "    r = []\n",
    "    for l in list:\n",
    "        c = np.array(l)\n",
    "        if (c==[0,0]).all():\n",
    "            r.append(1)\n",
    "        elif (c==[0,1]).all():\n",
    "            r.append(2)\n",
    "        elif (c==[1,0]).all():\n",
    "            r.append(3)\n",
    "        elif (c==[1,1]).all():\n",
    "            r.append(4)\n",
    "        else:\n",
    "            r.append(5)\n",
    "    return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "data = pd.DataFrame(pd.read_csv('../data/alcohol2.csv'))\n",
    "X = (data).to_numpy()[:,:16]\n",
    "Y = (data).to_numpy()[:,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Target transform\n",
    "\n",
    "# class 1--4 --> alcohol consumption (1=low, 4=high)\n",
    "val_map = {1: [0,0], 2: [0,1], 3: [1,0], 4: [1,1]}\n",
    "T = np.array([val_map[y] for y in Y])\n",
    "data['alcohol_consumption'] = data['alcohol_consumption'].map( {1: [0,0], 2: [0,1], 3: [1,0], 4: [1,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualization of input data in curves\n",
    "\n",
    "for column in data:\n",
    "    feature = data[column]\n",
    "    if column != 'alcohol_consumption':\n",
    "        x_axis = []\n",
    "        y_axis = []\n",
    "        for i in range(1,5):\n",
    "            indices = np.where(Y == i)\n",
    "            feature_filtrated = np.array(feature)[indices]\n",
    "            unique, counts = np.unique(feature_filtrated, return_counts=True)\n",
    "            y_axis.append(counts)\n",
    "            x_axis.append(unique)\n",
    "        np_y_axis = np.array(y_axis)\n",
    "        np_x_axis = np.array(x_axis)\n",
    "        labels = ['very low','low','medium','high and very high']\n",
    "        plt.plot(np_x_axis[0],np_y_axis[0],label=labels[0])\n",
    "        plt.plot(np_x_axis[1],np_y_axis[1],label=labels[1])\n",
    "        plt.plot(np_x_axis[2],np_y_axis[2],label=labels[2])\n",
    "        plt.plot(np_x_axis[3],np_y_axis[3],label=labels[3])\n",
    "        plt.legend()\n",
    "        plt.xlabel(column, fontsize=18)\n",
    "        plt.ylabel('Count', fontsize=16)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualization of input data in histograms\n",
    "\n",
    "dataVisualize = pd.DataFrame(pd.read_csv('../data/alcohol.csv'))\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "labels = ['very low','low','medium','high and very high']\n",
    "for i in data:\n",
    "    if i != 'alcohol_consumption' and i != 'absences' and i != 'final_grade':\n",
    "        plt.figure(i)\n",
    "        fig = sns.countplot(x=\"alcohol_consumption\", hue=i, data=dataVisualize)\n",
    "        fig.set(xlabel=i, ylabel='Count')\n",
    "        plt.title(\"Dependency of level of alcohol on {}\".format(i))\n",
    "        fig.set_xticklabels(labels, rotation=45)\n",
    "        plt.show\n",
    "        \n",
    "# different view with multiple attributes\n",
    "g = sns.catplot(x=\"study_time\", hue=\"sex\", col=\"alcohol_consumption\",\n",
    "                data=dataVisualize, kind=\"count\",\n",
    "                height=4, aspect=.7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Pre-process data using MinMaxScaler() [0,1]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_process = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants\n",
    "\n",
    "train_and_valid = 0.90 # CAN BE CHANGED\n",
    "valid_fix = 0.20 # DO NOT CHANGE !!!\n",
    "train_calc = train_and_valid * (1 - valid_fix)\n",
    "valid_calc = train_and_valid - train_calc\n",
    "test_calc = 1 - train_calc - valid_calc\n",
    "\n",
    "train_fraction=train_calc\n",
    "validation_fraction=valid_calc\n",
    "test_fraction=test_calc\n",
    "\n",
    "hidden_layer_neurons = 8\n",
    "output_layer_neurons = 2\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "alpha=0.001\n",
    "goal = 1e-5\n",
    "tolerance=0.0001\n",
    "max_iterations=10000\n",
    "k_cross_validation = 5\n",
    "\n",
    "#X_train = 64% of features\n",
    "#X_validation = 16% of features\n",
    "#X_test = 20% of features\n",
    "\n",
    "#T_train = 64 % of targets\n",
    "#T_validation = 16% of targets\n",
    "#T_test = 20% of targets\n",
    "\n",
    "#X2_train = 80% of features\n",
    "#X2_test = 20% of features\n",
    "\n",
    "#T2_train = 80% of targets\n",
    "#T2_test = 20% of targets\n",
    "\n",
    "split_sizes = [int(len(X_process)*train_fraction), int(len(X_process)*(train_fraction+validation_fraction))]\n",
    "X_train,X_validation,X_test = np.split(X_process, split_sizes)\n",
    "T_train,T_validation,T_test = np.split(T, split_sizes)\n",
    "X2_train, X2_test, T2_train, T2_test = train_test_split(\n",
    "    X_process, T, \n",
    "    train_size=train_fraction+validation_fraction, \n",
    "    test_size=test_fraction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train & Validate (Neurolab feed-forward backpropagation network with custom validation implementation)\n",
    "\n",
    "# Create a neural network (Multilayer feed forward perceptron)\n",
    "net = nl.net.newff(nl.tool.minmax(X_process),[hidden_layer_neurons,output_layer_neurons])\n",
    "\n",
    "# Change the transfer function for the output layer\n",
    "net.layers[0].transf = nl.trans.LogSig() # hidden layer\n",
    "net.layers[1].transf = nl.trans.LogSig() # output layer\n",
    "\n",
    "# Train the network & Simulate validation\n",
    "i = 1\n",
    "i_max = max_iterations\n",
    "previous_accuracy = 0\n",
    "can_try_again = True\n",
    "while i <= i_max:\n",
    "    print\"\\nRepetitions count:\", i\n",
    "    error = net.trainf = nl.train.train_rprop(net, X_train, T_train, epochs=epochs, show=10, lr=learning_rate, goal=0)\n",
    "    \n",
    "    plt.plot(error)\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel('Train error (SSE)')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    out_validation = net.sim(X_validation)\n",
    "    out_validation = np.around(out_validation)\n",
    "    \n",
    "    accuracy = np.mean(out_validation == T_validation)\n",
    "    error_accuracy = 1 - accuracy\n",
    "    \n",
    "    print\"Validation success:\", accuracy*100, \"%\"\n",
    "    print\"Validation error:\", error_accuracy*100, \"%\"\n",
    "    print\"Number of layers:\", len(net.layers)\n",
    "    print\"Learning rate:\", learning_rate\n",
    "    \n",
    "    for n in range(0,len(net.layers)):\n",
    "        print\"Weights of\", n, \"layer:\", net.layers[n].np['w']\n",
    "        print\"Biases of\", n, \"layer:\", net.layers[n].np['b']\n",
    "    \n",
    "    if (accuracy-previous_accuracy <= tolerance) or (i >= i_max):\n",
    "        if (can_try_again):\n",
    "            previous_accuracy = accuracy\n",
    "            i+=1 #training continues\n",
    "            can_try_again = False\n",
    "        i=i_max+1 #training stops\n",
    "    else:\n",
    "        previous_accuracy = accuracy\n",
    "        i+=1 #training continues\n",
    "        can_try_again = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict (Neurolab feed-forward backpropagation network with custom validation implementation)\n",
    "\n",
    "out_test = net.sim(X_test)\n",
    "out_test = np.around(out_test)\n",
    "accuracy = np.mean(out_test == T_test)\n",
    "print\"Success:\", round(accuracy * 100, 2), \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare the results with target data (Neurolab feed-forward backpropagation network with custom validation implementation)\n",
    "\n",
    "T_val_converted = convert(T_validation)\n",
    "T_test_converted = convert(T_test)\n",
    "out_val_converted = convert(out_validation)\n",
    "out_test_converted = convert(out_test)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(T_val_converted,'p')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Target output of validation data')\n",
    "plt.xticks(np.arange(0, 130, 20)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(out_val_converted,'p')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Simulation output on validation data')\n",
    "plt.xticks(np.arange(0, 130, 20)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(T_test_converted,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Target output on test data')\n",
    "plt.xticks(np.arange(0, 130, 20)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(out_test_converted,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Simulation output on test data')\n",
    "plt.xticks(np.arange(0, 130, 20)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare 10 random patterns (Neurolab feed-forward backpropagation network with custom validation implementation)\n",
    "\n",
    "T_test_converted = convert(T_test)\n",
    "out_test_converted = convert(out_test)\n",
    "length = 10\n",
    "chosen_out_test = []\n",
    "chosen_T_test = []\n",
    "rand_numbers = np.sort(np.random.randint(len(T_test_converted), size=(length)))\n",
    "for i in rand_numbers:\n",
    "    chosen_out_test.append(out_test_converted[i])\n",
    "    chosen_T_test.append(T_test_converted[i])\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(chosen_T_test,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Target output on test data')\n",
    "plt.xticks(np.arange(0, 10, 1)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(chosen_out_test,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Simulation output on test data')\n",
    "plt.xticks(np.arange(0, 10, 1)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train & Validate (Scikit-learn MLPClassifier)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    activation='logistic', \n",
    "    alpha=alpha, \n",
    "    batch_size='auto', \n",
    "    early_stopping=False, \n",
    "    hidden_layer_sizes=(hidden_layer_neurons), \n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=learning_rate, \n",
    "    max_iter=max_iterations,\n",
    "    shuffle=True,\n",
    "    solver='adam',\n",
    "    tol=tolerance,\n",
    "    validation_fraction=validation_fraction,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 519 je 80% 649, počet prvkov predanych v parametre Y a \n",
    "# y sa rovna a z neho použije 80% ako training a \n",
    "# 20% ako validation a tých 80% je maximalna posledna hodnota čo môže byť v training_size\n",
    "\n",
    "train_sizes = [1,100,200,400,467] #649*0,90*0,80=467\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    estimator = mlp,\n",
    "    X = X2_train,\n",
    "    y = T2_train, \n",
    "    train_sizes = train_sizes, \n",
    "    cv = k_cross_validation,\n",
    "    scoring = 'neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "print'Training scores:', train_scores\n",
    "print'Validation scores:', validation_scores\n",
    "\n",
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "print'Mean training scores', pd.Series(train_scores_mean, index = train_sizes)\n",
    "print'Mean validation scores',pd.Series(validation_scores_mean, index = train_sizes)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim(0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train & Predict (Scikit-learn MLPClassifier)\n",
    "\n",
    "mlp.fit(X_train,T_train)\n",
    "out_test = mlp.predict(X_test)\n",
    "scores = mlp.score(X_test, T_test)\n",
    "\n",
    "print(confusion_matrix(convert(T_test),convert(out_test)))\n",
    "print(classification_report(T_test,out_test))\n",
    "print\"Success:\", round(scores * 100, 2), \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare the results with target data (Scikit-learn MLPClassifier)\n",
    "\n",
    "T_test_converted = convert(T_test)\n",
    "out_test_converted = convert(out_test)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(T_test_converted,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Target output on test data')\n",
    "plt.xticks(np.arange(0, 130, 20)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(out_test_converted,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Simulation output on test data')\n",
    "plt.xticks(np.arange(0, 130, 20)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare 10 random patterns (Scikit-learn MLPClassifier)\n",
    "\n",
    "T_test_converted = convert(T_test)\n",
    "out_test_converted = convert(out_test)\n",
    "length = 10\n",
    "chosen_out_test = []\n",
    "chosen_T_test = []\n",
    "rand_numbers = np.sort(np.random.randint(len(T_test_converted), size=(length)))\n",
    "for i in rand_numbers:\n",
    "    chosen_out_test.append(out_test_converted[i])\n",
    "    chosen_T_test.append(T_test_converted[i])\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(chosen_T_test,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Target output on test data')\n",
    "plt.xticks(np.arange(0, 10, 1)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(chosen_out_test,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Simulation output on test data')\n",
    "plt.xticks(np.arange(0, 10, 1)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train & Validate (Scikit-learn LinearRegression)\n",
    "\n",
    "mlp = LinearRegression()\n",
    "\n",
    "# 519 je 80% 649, počet prvkov predanych v parametre Y a \n",
    "# y sa rovna a z neho použije 80% ako training a \n",
    "# 20% ako validation a tých 80% je maximalna posledna hodnota čo môže byť v training_size\n",
    "\n",
    "train_sizes = [1,100,200,400,467] #649*0,90*0,80=467\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    estimator = mlp,\n",
    "    X = X2_train,\n",
    "    y = T2_train, \n",
    "    train_sizes = train_sizes, \n",
    "    cv = k_cross_validation,\n",
    "    scoring = 'neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "print'Training scores:', train_scores\n",
    "print'Validation scores:', validation_scores\n",
    "\n",
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "print'Mean training scores', pd.Series(train_scores_mean, index = train_sizes)\n",
    "print'Mean validation scores',pd.Series(validation_scores_mean, index = train_sizes)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim(0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train & Predict (Scikit-learn LinearRegression)\n",
    "\n",
    "mlp.fit(X_train,T_train)\n",
    "out_test = mlp.predict(X_test)\n",
    "scores = mlp.score(X_test, T_test)\n",
    "\n",
    "out_test = np.around(out_test)\n",
    "accuracy = np.mean(out_test == T_test)\n",
    "\n",
    "print(confusion_matrix(convert(T_test),convert(out_test)))\n",
    "print(classification_report(T_test,out_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare the results with target data (Scikit-learn LinearRegression)\n",
    "\n",
    "T_test_converted = convert(T_test)\n",
    "out_test_converted = convert(out_test)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(T_test_converted,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Target output on test data')\n",
    "plt.xticks(np.arange(0, 130, 20)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(out_test_converted,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Simulation output on test data')\n",
    "plt.xticks(np.arange(0, 130, 20)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare 10 random patterns (Scikit-learn LinearRegression)\n",
    "\n",
    "T_test_converted = convert(T_test)\n",
    "out_test_converted = convert(out_test)\n",
    "length = 10\n",
    "chosen_out_test = []\n",
    "chosen_T_test = []\n",
    "rand_numbers = np.sort(np.random.randint(len(T_test_converted), size=(length)))\n",
    "for i in rand_numbers:\n",
    "    chosen_out_test.append(out_test_converted[i])\n",
    "    chosen_T_test.append(T_test_converted[i])\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(chosen_T_test,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Target output on test data')\n",
    "plt.xticks(np.arange(0, 10, 1)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(chosen_out_test,'ro')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Sample')\n",
    "plt.title('Simulation output on test data')\n",
    "plt.xticks(np.arange(0, 10, 1)) \n",
    "plt.yticks(np.arange(1, 5, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error analysis - decision on which attributes to remove depending on mode of features\n",
    "# if mode > 70% remove from dataset, otherwise it can remain\n",
    "\n",
    "indices = []\n",
    "for index in range(len(T_validation)):\n",
    "        equal = np.array_equal(T_validation[index], out_validation[index])\n",
    "        if not equal:\n",
    "            indices.append(index)\n",
    "            \n",
    "notEqualdata = []\n",
    "j = 0\n",
    "for i in indices:\n",
    "    notEqualdata.append(X_validation[i,:])\n",
    "    j += 1\n",
    "    \n",
    "equaldataLength = len(notEqualdata)\n",
    "\n",
    "notEqualdata = np.array(pd.DataFrame(notEqualdata))\n",
    "invertedTable = min_max_scaler.inverse_transform(notEqualdata)\n",
    "\n",
    "mode = []\n",
    "modeCount = []\n",
    "for i in range(16):\n",
    "    column = invertedTable[:,i]\n",
    "    mode.append(stats.mode(column))\n",
    "    modeCount.append(stats.mode(column).count)\n",
    "\n",
    "modeCount = np.array(modeCount).ravel()\n",
    "modeCount = modeCount.astype(float)\n",
    "\n",
    "modeTable = pd.DataFrame(mode)\n",
    "modeTable = modeTable.astype(float)\n",
    "\n",
    "relativeCount = [x / equaldataLength for x in modeCount]\n",
    "modeTable = modeTable.assign(percentage = relativeCount)\n",
    "\n",
    "removebooleans = [ x > 0.70 for x in relativeCount]\n",
    "modeTable = modeTable.assign(remove = removebooleans)\n",
    "print(modeTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error analysis - decision on which attributes to remove depending on mode of features\n",
    "# if mode > 70% remove from dataset, otherwise it can remain\n",
    "\n",
    "indices = []\n",
    "for index in range(len(T_test)):\n",
    "        equal = np.array_equal(T_test[index], out_test[index])\n",
    "        if not equal:\n",
    "            indices.append(index)\n",
    "            \n",
    "notEqualdata = []\n",
    "j = 0\n",
    "for i in indices:\n",
    "    notEqualdata.append(X_test[i,:])\n",
    "    j += 1\n",
    "    \n",
    "equaldataLength = len(notEqualdata)\n",
    "\n",
    "notEqualdata = np.array(pd.DataFrame(notEqualdata))\n",
    "invertedTable = min_max_scaler.inverse_transform(notEqualdata)\n",
    "\n",
    "mode = []\n",
    "modeCount = []\n",
    "for i in range(16):\n",
    "    column = invertedTable[:,i]\n",
    "    mode.append(stats.mode(column))\n",
    "    modeCount.append(stats.mode(column).count)\n",
    "\n",
    "modeCount = np.array(modeCount).ravel()\n",
    "modeCount = modeCount.astype(float)\n",
    "\n",
    "modeTable = pd.DataFrame(mode)\n",
    "modeTable = modeTable.astype(float)\n",
    "\n",
    "relativeCount = [x / equaldataLength for x in modeCount]\n",
    "modeTable = modeTable.assign(percentage = relativeCount)\n",
    "\n",
    "removebooleans = [ x > 0.70 for x in relativeCount]\n",
    "modeTable = modeTable.assign(remove = removebooleans)\n",
    "print(modeTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
